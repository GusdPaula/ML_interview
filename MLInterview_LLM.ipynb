{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkyji7fPlzEBbnZGo0Ertg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GusdPaula/ML_interview/blob/main/MLInterview_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP"
      ],
      "metadata": {
        "id": "GMhto_lvwbjj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13nCEnPfo8iz",
        "outputId": "94b19373-3d74-4d12-d701-6109c1b56f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language: 3\n",
            "nlp: 2\n",
            "human: 2\n",
            "natural: 1\n",
            "processing: 1\n",
            "fascinating: 1\n",
            "fiels: 1\n",
            "artifical: 1\n",
            "intelligence: 1\n",
            "ai: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "# download necessary NLTK data files\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample text corpus\n",
        "\n",
        "text_corpus = \"\"\"Natural Language Processing (NLP) is a fascinating fiels of Artifical Intelligence (AI) that focuses on the interaction between computers and human language.\n",
        "NLP techniques enable machines to understand and process human language.\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text_corpus.lower())\n",
        "\n",
        "# Remove punctuation and stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "cleaned_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "\n",
        "# Compute word frequencies\n",
        "word_frequencies = Counter(cleaned_tokens)\n",
        "\n",
        "# Print the most common words\n",
        "for word, frequency in word_frequencies.most_common(10):\n",
        "    print(f\"{word}: {frequency}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention mechanism"
      ],
      "metadata": {
        "id": "VqynHhoMwekP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Define Query(Q), Key (K), and Value (V) matrices\n",
        "Q = np.array([[1, 0, 1]]) # Query vector (1x3)\n",
        "K = np.array([[1, 1, 0], [1, 1, 0], [0, 0, 1]]) # Key vectors (3x3)\n",
        "V = np.array([[1, 2],\n",
        "              [0, 3],\n",
        "              [1, 1]]) # Value vectors (3x2)\n",
        "\n",
        "# Step 2: Compute dot product between Q and K^T (similarity scores)\n",
        "scores = np.dot(Q, K.T)\n",
        "\n",
        "# Step 3: Scale the scores (optinional but common)\n",
        "dk = Q.shape[1] # dimension of key vectors\n",
        "scaled_scores = scores / np.sqrt(dk)\n",
        "\n",
        "# Step 4: Compute softmax to get attention weights\n",
        "attention_weights = np.exp(scaled_scores) / np.sum(np.exp(scaled_scores), axis=1, keepdims=True)\n",
        "\n",
        "# Step 5: Multitly attention weights with values matrix to get output\n",
        "output = np.dot(attention_weights, V)\n",
        "\n",
        "# Display results\n",
        "print(\"Query (Q):\")\n",
        "print(Q)\n",
        "print(\"\\nKey Vectors (K):\")\n",
        "print(K)\n",
        "print(\"\\nValue Vectors (V):\")\n",
        "print(V)\n",
        "print(\"\\nAttention Weights:\")\n",
        "print(attention_weights)\n",
        "print(\"\\nScaled Scores:\")\n",
        "print(scaled_scores)\n",
        "print(\"\\nOutput:\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmg8xNdNqSKc",
        "outputId": "b975f689-42e2-4494-c1e7-2c368a719da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query (Q):\n",
            "[[1 0 1]]\n",
            "\n",
            "Key Vectors (K):\n",
            "[[1 1 0]\n",
            " [1 1 0]\n",
            " [0 0 1]]\n",
            "\n",
            "Value Vectors (V):\n",
            "[[1 2]\n",
            " [0 3]\n",
            " [1 1]]\n",
            "\n",
            "Attention Weights:\n",
            "[[0.33333333 0.33333333 0.33333333]]\n",
            "\n",
            "Scaled Scores:\n",
            "[[0.57735027 0.57735027 0.57735027]]\n",
            "\n",
            "Output:\n",
            "[[0.66666667 2.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT fine-tuning"
      ],
      "metadata": {
        "id": "poYWEWiewkzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==2.18.0"
      ],
      "metadata": {
        "id": "lz4IgrjPxK8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "aQXVj3f6wZKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained BERT and Tokenizer\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "id": "Gwwb4NWwuuMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the Dataset\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "snGYfoCLxwKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for training\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"./results\",\n",
        "                  eval_strategy=\"epoch\",\n",
        "                  per_device_train_batch_size=8,\n",
        "                  per_device_eval_batch_size=8,\n",
        "                  num_train_epochs=3,\n",
        "                  weight_decay=0.01)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=42).select(range(2000)),\n",
        "    eval_dataset=tokenized_datasets[\"test\"].shuffle(seed=42).select(range(500))\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "oC0HZd5uyH4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "GYXg_aGDzIhF",
        "outputId": "fd73a37f-51fd-4827-dd55-e851290ed0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 10:51]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.39584383368492126,\n",
              " 'eval_runtime': 662.6447,\n",
              " 'eval_samples_per_second': 0.755,\n",
              " 'eval_steps_per_second': 0.095,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions\n",
        "text = \"This movie was fantastic!\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "predicted_class = logits.argmax().item()\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj5n96u6z0_2",
        "outputId": "6bd357c5-4366-4960-cd80-a682390c5b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LYwbp8U0Gr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}